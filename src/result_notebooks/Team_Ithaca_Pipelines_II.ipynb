{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Imports necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bootcampviztools as bt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import  train_test_split, GridSearchCV\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score, confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc, classification_report\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "import lightgbm as lgb\n",
    "import os\n",
    "import dill\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Carga de datos de Test e identificaci√≥n de columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../data/test.csv', index_col=0)\n",
    "\n",
    "# Ponemos 'id' como √≠ndice\n",
    "df_test = df_test.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 18) (2120849580.py, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[3], line 18\u001b[1;36m\u001b[0m\n\u001b[1;33m    ''''\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 18)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "#Identificar tipos de columnas\n",
    "numerical_cols = ['Age', 'Flight Distance', 'Departure Delay in Minutes', 'Arrival Delay in Minutes']\n",
    "binary_cols = [col for col in df_test.select_dtypes(include=['object']).columns if df_test[col].nunique() == 2]\n",
    "\n",
    "# Quitar el target\n",
    "binary_cols.remove('satisfaction')\n",
    "\n",
    "# Establecer el target\n",
    "target = 'satisfaction'\n",
    "\n",
    "\n",
    "onehot_cols = [col for col in df_test.columns if col not in numerical_cols and col not in binary_cols and col not in target]\n",
    "\n",
    "\n",
    "#features numericas a las que aplicar logaritmo:\n",
    "numerical_cols_log = [col for col in numerical_cols if col != 'Age']'\n",
    "''''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Cargamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('null_handling',\n",
      "                 Pipeline(steps=[('drop_high_nulls', DropHighNullColumns()),\n",
      "                                 ('drop_remaining_nulls', DropRemainingNulls()),\n",
      "                                 ('drop_duplicates', DropDuplicates())])),\n",
      "                ('column_identification', IdentifyColumns()),\n",
      "                ('log_transform',\n",
      "                 FunctionTransformer(func=<function safe_log_transform at 0x0000022D95E928E0>)),\n",
      "                ('preprocessor',\n",
      "                 Pipeline(steps=[('pr...\n",
      "                                                                    'boarding',\n",
      "                                                                    'Seat '\n",
      "                                                                    'comfort',\n",
      "                                                                    'Inflight '\n",
      "                                                                    'entertainment',\n",
      "                                                                    'On-board '\n",
      "                                                                    'service',\n",
      "                                                                    'Leg room '\n",
      "                                                                    'service',\n",
      "                                                                    'Baggage '\n",
      "                                                                    'handling',\n",
      "                                                                    'Checkin '\n",
      "                                                                    'service',\n",
      "                                                                    'Inflight '\n",
      "                                                                    'service',\n",
      "                                                                    'Cleanliness']),\n",
      "                                                                  ('scaler',\n",
      "                                                                   StandardScaler(),\n",
      "                                                                   ['Age',\n",
      "                                                                    'Flight '\n",
      "                                                                    'Distance',\n",
      "                                                                    'Departure '\n",
      "                                                                    'Delay in '\n",
      "                                                                    'Minutes',\n",
      "                                                                    'Arrival '\n",
      "                                                                    'Delay in '\n",
      "                                                                    'Minutes'])]))])),\n",
      "                ('model',\n",
      "                 Pipeline(steps=[('model', LGBMClassifier(num_leaves=50))]))])\n"
     ]
    }
   ],
   "source": [
    "print(best_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "El archivo del modelo no se encontr√≥ en: ../src\\src/models/best_pipeline.pkl",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# ‚úÖ Cargar el pipeline entrenado\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(MODEL_PATH):\n\u001b[1;32m---> 15\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEl archivo del modelo no se encontr√≥ en: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMODEL_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(MODEL_PATH, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     18\u001b[0m     best_pipeline \u001b[38;5;241m=\u001b[39m dill\u001b[38;5;241m.\u001b[39mload(f)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: El archivo del modelo no se encontr√≥ en: ../src\\src/models/best_pipeline.pkl"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dill\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, classification_report\n",
    "\n",
    "# ‚úÖ Definir las rutas basadas en la estructura del directorio\n",
    "BASE_PATH = \"../src\"  # Ajustado a la estructura vista en la imagen\n",
    "MODEL_PATH = os.path.join(BASE_PATH, \"src/models/best_pipeline.pkl\")\n",
    "TEST_PATH = os.path.join(BASE_PATH, \"data/test.csv\")\n",
    "PREDICTIONS_PATH = os.path.join(BASE_PATH, \"data/predictions.csv\")\n",
    "\n",
    "# ‚úÖ Cargar el pipeline entrenado\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    raise FileNotFoundError(f\"El archivo del modelo no se encontr√≥ en: {MODEL_PATH}\")\n",
    "\n",
    "with open(MODEL_PATH, \"rb\") as f:\n",
    "    best_pipeline = dill.load(f)\n",
    "\n",
    "print(\"‚úÖ Modelo y preprocesador cargados exitosamente.\")\n",
    "\n",
    "# ‚úÖ Cargar los datos de test\n",
    "if not os.path.exists(TEST_PATH):\n",
    "    raise FileNotFoundError(f\"No se encontr√≥ el archivo de test en {TEST_PATH}\")\n",
    "\n",
    "df_test = pd.read_csv(TEST_PATH, index_col=0)  # `id` ya es √≠ndice\n",
    "\n",
    "# ‚úÖ Extraer la variable target si est√° presente\n",
    "if \"satisfaction\" in df_test.columns:\n",
    "    y_test = df_test[\"satisfaction\"].replace({\"neutral or dissatisfied\": 0, \"satisfied\": 1}).infer_objects(copy=False)\n",
    "    df_test = df_test.drop(columns=[\"satisfaction\"])\n",
    "else:\n",
    "    y_test = None  # Si no est√° presente, asumimos que se predice sin evaluaci√≥n\n",
    "\n",
    "# ‚úÖ Aplicar el pipeline completo al conjunto de test (preprocesamiento + modelo)\n",
    "y_pred = best_pipeline.predict(df_test)\n",
    "\n",
    "# ‚úÖ Evaluar el modelo si se tiene la columna 'satisfaction' en test\n",
    "if y_test is not None:\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    bal_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "    print(\"\\nüìä M√©tricas de Evaluaci√≥n:\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"Balanced Accuracy: {bal_acc:.4f}\")\n",
    "    print(\"\\nReporte de Clasificaci√≥n:\\n\", class_report)\n",
    "\n",
    "# ‚úÖ Guardar las predicciones en la estructura correcta\n",
    "predictions_df = pd.DataFrame({\"id\": df_test.index, \"prediction\": y_pred})\n",
    "predictions_df.to_csv(PREDICTIONS_PATH, index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Predicciones guardadas en {PREDICTIONS_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Aplicamos los pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocessor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Crear un pipeline que incluya el preprocesamiento antes del modelo\u001b[39;00m\n\u001b[0;32m      2\u001b[0m full_pipeline \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[1;32m----> 3\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreprocessor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mpreprocessor\u001b[49m),  \u001b[38;5;66;03m# Asegurar que el preprocesador se aplica a test\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_)  \u001b[38;5;66;03m# Modelo final con los mejores hiperpar√É¬°metros\u001b[39;00m\n\u001b[0;32m      5\u001b[0m ])\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Definir la ruta correcta para guardar el pipeline completo\u001b[39;00m\n\u001b[0;32m      8\u001b[0m MODEL_DIR \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mgetcwd(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msrc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'preprocessor' is not defined"
     ]
    }
   ],
   "source": [
    "# Crear un pipeline que incluya el preprocesamiento antes del modelo\n",
    "full_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),  # Asegurar que el preprocesador se aplica a test\n",
    "    (\"model\", grid_search.best_estimator_)  # Modelo final con los mejores hiperpar√É¬°metros\n",
    "])\n",
    "\n",
    "# Definir la ruta correcta para guardar el pipeline completo\n",
    "MODEL_DIR = os.path.join(os.getcwd(), \"..\", \"..\", \"src\", \"models\")\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "model_path = os.path.join(MODEL_DIR, \"best_pipeline.pkl\")\n",
    "\n",
    "# Guardar el pipeline completo\n",
    "with open(model_path, \"wb\") as f:\n",
    "    pickle.dump(full_pipeline, f)\n",
    "\n",
    "print(f\"Pipeline completo guardado en {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando pipeline desde c:\\Users\\maria\\Documents\\GitHub\\Pipelines_Airline_Passenger_Satisfaction\\src\\models\\LightGBM_optimized_pipeline.pkl...\n",
      "Pipeline cargado correctamente.\n",
      "Generando predicciones en los datos de test...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features_ is 93 and input n_features is 22",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Aplicar el pipeline y realizar predicciones\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerando predicciones en los datos de test...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\maria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py:601\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[1;34m(self, X, **params)\u001b[0m\n\u001b[0;32m    599\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(with_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    600\u001b[0m         Xt \u001b[38;5;241m=\u001b[39m transform\u001b[38;5;241m.\u001b[39mtransform(Xt)\n\u001b[1;32m--> 601\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    603\u001b[0m \u001b[38;5;66;03m# metadata routing enabled\u001b[39;00m\n\u001b[0;32m    604\u001b[0m routed_params \u001b[38;5;241m=\u001b[39m process_routing(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n",
      "File \u001b[1;32mc:\\Users\\maria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\lightgbm\\sklearn.py:1321\u001b[0m, in \u001b[0;36mLGBMClassifier.predict\u001b[1;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, validate_features, **kwargs)\u001b[0m\n\u001b[0;32m   1309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict\u001b[39m(\n\u001b[0;32m   1310\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1311\u001b[0m     X: _LGBM_ScikitMatrixLike,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1318\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   1319\u001b[0m ):\n\u001b[0;32m   1320\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1321\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1322\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1324\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1326\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpred_leaf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpred_leaf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpred_contrib\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpred_contrib\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1329\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1331\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_objective) \u001b[38;5;129;01mor\u001b[39;00m raw_score \u001b[38;5;129;01mor\u001b[39;00m pred_leaf \u001b[38;5;129;01mor\u001b[39;00m pred_contrib:\n\u001b[0;32m   1332\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\maria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\lightgbm\\sklearn.py:1351\u001b[0m, in \u001b[0;36mLGBMClassifier.predict_proba\u001b[1;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, validate_features, **kwargs)\u001b[0m\n\u001b[0;32m   1339\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict_proba\u001b[39m(\n\u001b[0;32m   1340\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1341\u001b[0m     X: _LGBM_ScikitMatrixLike,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1348\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   1349\u001b[0m ):\n\u001b[0;32m   1350\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Docstring is set after definition, using a template.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1351\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1352\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1353\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1354\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1355\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpred_leaf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpred_leaf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1357\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpred_contrib\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpred_contrib\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1358\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1359\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1360\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1361\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_objective) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (raw_score \u001b[38;5;129;01mor\u001b[39;00m pred_leaf \u001b[38;5;129;01mor\u001b[39;00m pred_contrib):\n\u001b[0;32m   1362\u001b[0m         _log_warning(\n\u001b[0;32m   1363\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot compute class probabilities or labels \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1364\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdue to the usage of customized objective function.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1365\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning raw scores instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1366\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\maria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\lightgbm\\sklearn.py:1010\u001b[0m, in \u001b[0;36mLGBMModel.predict\u001b[1;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, validate_features, **kwargs)\u001b[0m\n\u001b[0;32m   1008\u001b[0m n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_features \u001b[38;5;241m!=\u001b[39m n_features:\n\u001b[1;32m-> 1010\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1011\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of features of the model must \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1012\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatch the input. Model n_features_ is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1013\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput n_features is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1014\u001b[0m     )\n\u001b[0;32m   1015\u001b[0m \u001b[38;5;66;03m# retrieve original params that possibly can be used in both training and prediction\u001b[39;00m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;66;03m# and then overwrite them (considering aliases) with params that were passed directly in prediction\u001b[39;00m\n\u001b[0;32m   1017\u001b[0m predict_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_params(stage\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features_ is 93 and input n_features is 22"
     ]
    }
   ],
   "source": [
    "# Cargar el pipeline entrenado\n",
    "print(f\"Cargando pipeline desde {model_path}...\")\n",
    "with open(model_path, \"rb\") as f:\n",
    "    pipeline = pickle.load(f)\n",
    "\n",
    "print(\"Pipeline cargado correctamente.\")\n",
    "\n",
    "# Separar caracter√≠sticas y variable objetivo\n",
    "X_test = df_test.drop(columns=[\"satisfaction\"])\n",
    "y_test = df_test[\"satisfaction\"]\n",
    "\n",
    "# Aplicar el pipeline y realizar predicciones\n",
    "print(\"Generando predicciones en los datos de test...\")\n",
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. M√©tricas de evaluaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "# Convertir el reporte en un DataFrame\n",
    "report_df = pd.DataFrame(report).T  # Transponer para mejor visualizaci√≥n\n",
    "\n",
    "# Mostrar el classification report como tabla\n",
    "report_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La primera m√©trica escogida se trata de la matriz de confusi√≥n ya que nos permite tener una visi√≥n de varias m√©tricas a la vez, adem√°s de percibir si ha habido sobreajuste de datos.\n",
    "\n",
    "Tal y como se observa, nuestro modelo optimizado optiene un XX% de accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de Confusi√≥n\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.title(f\"Matriz de Confusi√≥n - {best_model_name}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importancia de caracter√≠sticas (solo para modelos de √°rboles)\n",
    "if best_model_name in [\"RandomForest\", \"GradientBoosting\", \"LightGBM\"]:\n",
    "    importances = best_model.named_steps[\"model\"].feature_importances_\n",
    "    feature_names = X_train.columns\n",
    "\n",
    "    # Crear un DataFrame ordenado por importancia\n",
    "    feature_importance_df = pd.DataFrame({\"Feature\": feature_names, \"Importance\": importances})\n",
    "    feature_importance_df = feature_importance_df.sort_values(by=\"Importance\", ascending=False).head(20)  # Mostrar solo las 20 m√°s importantes\n",
    "\n",
    "    # Graficar la importancia de caracter√≠sticas\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(x=feature_importance_df[\"Importance\"], y=feature_importance_df[\"Feature\"], palette=\"Blues_r\")\n",
    "\n",
    "    # Etiquetas y t√≠tulo\n",
    "    plt.title(f\"Importancia de Caracter√≠sticas - {best_model_name}\", fontsize=14)\n",
    "    plt.xlabel(\"Importancia\", fontsize=12)\n",
    "    plt.ylabel(\"Caracter√≠sticas\", fontsize=12)\n",
    "\n",
    "    # Ajustar etiquetas para mejor legibilidad\n",
    "    plt.xticks(fontsize=10)\n",
    "    plt.yticks(fontsize=10)\n",
    "\n",
    "    # Mostrar valores sobre las barras\n",
    "    for index, value in enumerate(feature_importance_df[\"Importance\"]):\n",
    "        plt.text(value + 2, index, f\"{value:.2f}\", fontsize=10, verticalalignment=\"center\")\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
